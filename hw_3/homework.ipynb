{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interaction with the World Homework (#3)\n",
    "Python Computing for Data Science (c) J Bloom, UC Berkeley, 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Monty: The Python Siri\n",
    "\n",
    "Let's make a Siri-like program with the following properties:\n",
    "   - record your voice command\n",
    "   - use a webservice to parse that sound file into text\n",
    "   - based on what the text, take three different types of actions:\n",
    "       - send an email to yourself\n",
    "       - do some math\n",
    "       - tell a joke\n",
    "\n",
    "So for example, if you say \"Monty: email me with subject hello and body goodbye\", it will email you with the appropriate subject and body. If you say \"Monty: tell me a joke\" then it will go to the web and find a joke and print it for you. If you say, \"Monty: calculate two times three\" it should response with printing the number 6.\n",
    "\n",
    "Hint: you can use speed-to-text apps like Houndify to return the text (but not do the actions). You'll need to sign up for a free API and then follow documentation instructions for using the service within Python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# you need to install the following package to continue:\n",
    "#     pip3 install SpeechRecognition\n",
    "\n",
    "# load monty class\n",
    "from monty import Monty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demo, first load gmail login info\n",
    "To test on other computers, please manually define \n",
    "- monty_gmail\n",
    "- monty_password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_gmail_credential():\n",
    "    \"\"\"\n",
    "    Get Monty's gmail login credentials.\n",
    "    -----------------------------------------\n",
    "    | Only works on Yuguang Tong's computer |\n",
    "    -----------------------------------------\n",
    "    \n",
    "    return\n",
    "    ------\n",
    "        (username, password)\n",
    "    \"\"\"\n",
    "    import netrc\n",
    "\n",
    "    host = 'test_gmail'\n",
    "    secrets = netrc.netrc()\n",
    "    username, _, password = secrets.authenticators(host)\n",
    "    return username, password\n",
    "\n",
    "# this won't work on your computer, change it to your \"testing\" email address\n",
    "monty_gmail, monty_password = get_gmail_credential()\n",
    "\n",
    "# which email you want monty to send to?\n",
    "user_email = 'tongyuguang09@gmail.com' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make an instance of monty!\n",
    "monty = Monty(monty_gmail, monty_password, user_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run this as many times as you like\n",
    "# might be a bit slow \n",
    "monty.ask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Write a program that identifies musical notes from sound (AIFF) files. \n",
    "\n",
    "  - Run it on the supplied sound files (12) and report your program’s results. \n",
    "  - Use the labeled sounds (4) to make sure it works correctly. The provided sound files contain 1-3 simultaneous notes from different organs.\n",
    "  - Save copies of any example plots to illustrate how your program works.\n",
    "  \n",
    "  https://piazza.com/berkeley/fall2016/ay250/resources -> hw3_sound_files.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hints: You’ll want to decompose the sound into a frequency power spectrum. Use a Fast Fourier Transform. Be care about “unpacking” the string hexcode into python data structures. The sound files use 32 bit data. Play around with what happens when you convert the string data to other integer sizes, or signed vs unsigned integers. Also, beware of harmonics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import aifc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def aif_psd(file):\n",
    "    \"\"\"\n",
    "    1, open an AIFF file (known format, 2 channels, 16bit sample size) \n",
    "    2, extract amplitude\n",
    "    3, perform FFT to obtain power spectral density (PSD),\n",
    "    4, smooth PSD by a low pass filter\n",
    "    \n",
    "    \n",
    "    return \n",
    "    ------\n",
    "    freq: frequency in Hz\n",
    "    smoothed_spec: sqrt(PSD)\n",
    "    \"\"\"\n",
    "    # opn AIFF file\n",
    "    aif = aifc.open(file, 'rb')\n",
    "    # get number of frames\n",
    "    nframes = aif.getnframes()\n",
    "    # unpack samples and convert to signed 16-bit int\n",
    "    amp = np.fromstring(aif.readframes(nframes), dtype=np.int16)\n",
    "\n",
    "    # we only use left channel to obtain psd\n",
    "    left_ts = amp[::2]\n",
    "    spec = np.abs(np.fft.rfft(left_ts))\n",
    "\n",
    "    # sampling frequency\n",
    "    fs = aif.getframerate()\n",
    "    freq = np.arange(len(spec)) * fs / nframes\n",
    "    \n",
    "    from smooth import smooth\n",
    "    \n",
    "    # use low pass filters to smooth PSD\n",
    "    smoothed_spec = smooth(spec, window_len=24, window='hamming')\n",
    "    return (freq, smoothed_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demonstrating correctness by identifying notes from labeled samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.layouts import gridplot\n",
    "from bokeh.plotting import figure, output_notebook, show, output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To reproduce the result below, you need to put the data directory sound_files/ in the directory containing this notebook\n",
    "\n",
    "The demo plots are \"labeled_demo.html\" and \"unlabeled_demo.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_names = ['A4_PopOrgan', 'C4+A4_PopOrgan', 'F3_PopOrgan', 'F4_CathedralOrgan']\n",
    "labeled_files = ['sound_files/'+sample + '.aif' for sample in labeled_names]\n",
    "labeled_psds = [aif_psd(file) for file in labeled_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output_notebook()\n",
    "output_file('labeled_demo.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s= {}\n",
    "fmax = 1000\n",
    "x_range = [0, fmax]\n",
    "TOOLS=\"reset,crosshair,pan,wheel_zoom,box_zoom\"\n",
    "for i in range(4):\n",
    "    s[i] = figure(width=250, plot_height=250, title=labeled_names[i], \n",
    "                 x_axis_label='f[Hz]', y_axis_label='PSD', \n",
    "                 x_range = x_range, tools=TOOLS)\n",
    "    freq = np.array(labeled_psds[i][0])\n",
    "    psd = np.array(labeled_psds[i][1])\n",
    "    ind = freq < fmax\n",
    "    freq = freq[ind]\n",
    "    psd = psd[ind]\n",
    "    s[i].line(freq, psd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = gridplot([[s[0], s[1]], [s[2], s[3]]])\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now process unlabeled files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unlabeled_names = [str(sample)+'.aif' for sample in np.arange(1,13)]\n",
    "unlabeled_files = ['sound_files/'+ name for name in unlabeled_names]\n",
    "unlabeled_psds = [aif_psd(file) for file in unlabeled_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s= {}\n",
    "fmax = 1500\n",
    "x_range = [0, fmax]\n",
    "TOOLS=\"reset,crosshair,pan,wheel_zoom,box_zoom\"\n",
    "for i in range(12):\n",
    "    s[i] = figure(width=250, plot_height=250, title=unlabeled_names[i], \n",
    "                 x_axis_label='f[Hz]', y_axis_label='PSD', \n",
    "                 x_range = x_range, tools=TOOLS)\n",
    "    freq = np.array(unlabeled_psds[i][0])\n",
    "    psd = np.array(unlabeled_psds[i][1])\n",
    "    ind = freq < fmax\n",
    "    freq = freq[ind]\n",
    "    psd = psd[ind]\n",
    "    s[i].line(freq, psd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# output_notebook()\n",
    "output_file('unlabeled_demo.html')\n",
    "grid = np.array([s[i] for i in range(12)]).reshape(4,3).tolist()\n",
    "p = gridplot(grid)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1.aif PSD peaks at ~ 250, 390Hz --> B3, G3\n",
    "- 2.aif PSD peaks at ~ 350, 520, 695Hz --> F4, C5\n",
    "- 3.aif PSD peaks at ~ 440Hz --> A4\n",
    "- 4.aif PSD peaks at ~ 260Hz --> C4\n",
    "- 5.aif PSD peaks at ~ 293Hz --> D4\n",
    "- 6.aif PSD peaks at ~ 525Hz --> C5\n",
    "- 7.aif PSD peaks at ~ 589Hz --> D5\n",
    "- 8.aif PSD peaks at ~ 350, 695Hz --> F4\n",
    "- 9.aif PSD peaks at ~ 195, 390, 590Hz etc --> G3\n",
    "- 10.aif PSD peaks at ~ 260, 390, 1050Hz etc --> C4, G4\n",
    "- 11.aif PSD peaks at ~ 245, 990, 1320HZ etc --> B3\n",
    "- 12.aif PSD peaks at ~ 65, 131Hz etc --> C2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
